{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56582ce-fa81-4652-bbfd-b4602882e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7bd24eb-0066-49d7-8a87-effde9a657c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377078b6-369b-45d0-815b-f14a011c5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341236f6-aaea-4ce3-819f-5df79c4dac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd179fa-172c-495a-ba3a-74f7efb42f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16b1dda-948a-4154-bc7a-3ec3c8ebdd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e02941-eec0-493b-9493-d30c732e283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4fe204-d944-416a-93d3-bfcef1b69d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\syscom\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\syscom\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197bc631-0ff0-4cd7-a343-5cedde5ec084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    failed_images = []\n",
    "    \n",
    "    for i, image in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "        try:\n",
    "            # Load image with specified target size and color mode\n",
    "            img = load_img(image, target_size=(48, 48), color_mode='grayscale')\n",
    "            # Convert to numpy array\n",
    "            img = np.array(img)\n",
    "            # Normalize pixel values to 0-1 range\n",
    "            img = img / 255.0\n",
    "            features.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading image {image}: {e}\")\n",
    "            failed_images.append(image)\n",
    "            continue\n",
    "    \n",
    "    if failed_images:\n",
    "        print(f\"⚠️  Failed to load {len(failed_images)} images out of {len(images)}\")\n",
    "    \n",
    "    features = np.array(features)\n",
    "    # Reshape for CNN: (samples, height, width, channels)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    \n",
    "    print(f\"✅ Successfully extracted features from {len(features)} images\")\n",
    "    print(f\"📊 Features shape: {features.shape}\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a2d602-e080-42ac-8da9-7e191d880f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Extracting training features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2defcee7f0304400ab9ac4bff9d20597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully extracted features from 28821 images\n",
      "📊 Features shape: (28821, 48, 48, 1)\n",
      "🔄 Extracting test features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e49e0e27a24c51ad267e23b497b4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully extracted features from 7066 images\n",
      "📊 Features shape: (7066, 48, 48, 1)\n",
      "\n",
      "📈 Training set: 28821 samples\n",
      "📈 Test set: 7066 samples\n",
      "🎯 Unique labels in training: 7\n",
      "🎯 Label distribution in training:\n",
      "label\n",
      "happy       7164\n",
      "neutral     4982\n",
      "sad         4938\n",
      "fear        4103\n",
      "angry       3993\n",
      "surprise    3205\n",
      "disgust      436\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract features with progress tracking\n",
    "print(\"🔄 Extracting training features...\")\n",
    "train_features = extract_features(train['image'])\n",
    "\n",
    "print(\"🔄 Extracting test features...\")\n",
    "test_features = extract_features(test['image'])\n",
    "\n",
    "# Additional debugging information\n",
    "print(f\"\\n📈 Training set: {len(train_features)} samples\")\n",
    "print(f\"📈 Test set: {len(test_features)} samples\")\n",
    "print(f\"🎯 Unique labels in training: {train['label'].nunique()}\")\n",
    "print(f\"🎯 Label distribution in training:\\n{train['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f074cc32-e0ae-4398-8d62-fb5d87be5741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        images/train\\angry\\0.jpg\n",
      "1        images/train\\angry\\1.jpg\n",
      "2       images/train\\angry\\10.jpg\n",
      "3    images/train\\angry\\10002.jpg\n",
      "4    images/train\\angry\\10016.jpg\n",
      "Name: image, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train['image'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23dd3124-384c-4234-a512-2cdf8a1c08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b02d2e35-d410-4174-bb52-c4d8ce425c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = load_img(train['image'][0], color_mode='grayscale')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b041eb3a-b85e-4f53-ba68-1c2a740db06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e81b66b-384b-46c3-89dd-1ce75500fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22f614c9-0b8a-4531-97ed-964ad7622133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa91c56d-44a7-431b-8916-a5cfbcd18664",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e137ba-f18a-4c01-848d-a0d98fb1cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 7)\n",
    "y_test = to_categorical(y_test, num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66662751-6ea4-4ffe-bf6f-9ba8d2210887",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# convolutional Layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d27ae14b-485e-4fa8-af92-4d53d3e13a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26ff6bcf-4cd4-4056-b673-8deb4d6c0f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y_train shape: (28821, 7, 7, 7)\n",
      "Original y_test shape: (7066, 7, 7, 7)\n",
      "Sample of y_train[0]:\n",
      "[[[1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]]]\n",
      "\n",
      "Unique values in y_train:\n",
      "[0. 1.]\n",
      "After first fix - y_train shape: (28821, 7)\n",
      "After first fix - y_test shape: (7066, 7)\n",
      "Sample y_train_fixed[0]: [1. 0. 0. 0. 0. 0. 0.]\n",
      "Sum of first sample: 1.0\n",
      "Using one-hot encoded labels\n",
      "Final y_train shape: (28821, 7)\n",
      "Final y_test shape: (7066, 7)\n",
      "Sample final y_train[0]: [1. 0. 0. 0. 0. 0. 0.]\n",
      "Sum of first few samples: [1. 1. 1. 1. 1.]\n",
      "Epoch 1/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 4s/step - accuracy: 0.2363 - loss: 1.8373 - val_accuracy: 0.2583 - val_loss: 1.8095\n",
      "Epoch 2/100\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 3s/step - accuracy: 0.2507 - loss: 1.8140 - val_accuracy: 0.2583 - val_loss: 1.8095\n",
      "Epoch 3/100\n",
      "\u001b[1m218/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m25s\u001b[0m 3s/step - accuracy: 0.2466 - loss: 1.8171"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 68\u001b[0m\n\u001b[0;32m     61\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     62\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     63\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     64\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Current shapes\n",
    "print(\"Original y_train shape:\", y_train.shape)\n",
    "print(\"Original y_test shape:\", y_test.shape)\n",
    "\n",
    "# Check what the labels actually contain\n",
    "print(\"Sample of y_train[0]:\")\n",
    "print(y_train[0])\n",
    "print(\"\\nUnique values in y_train:\")\n",
    "print(np.unique(y_train))\n",
    "\n",
    "# Solution 1: If labels are incorrectly shaped one-hot vectors\n",
    "# Convert (samples, 7, 7, 7) to (samples, 7) by taking the first slice\n",
    "if y_train.shape == (y_train.shape[0], 7, 7, 7):\n",
    "    # Take only the first dimension of the extra axes\n",
    "    y_train_fixed = y_train[:, :, 0, 0]  # Shape: (samples, 7)\n",
    "    y_test_fixed = y_test[:, :, 0, 0]    # Shape: (samples, 7)\n",
    "    \n",
    "    print(\"After first fix - y_train shape:\", y_train_fixed.shape)\n",
    "    print(\"After first fix - y_test shape:\", y_test_fixed.shape)\n",
    "    \n",
    "    # Check if these look like proper one-hot vectors\n",
    "    print(\"Sample y_train_fixed[0]:\", y_train_fixed[0])\n",
    "    print(\"Sum of first sample:\", np.sum(y_train_fixed[0]))\n",
    "    \n",
    "    # If they're proper one-hot vectors (sum should be 1), use them\n",
    "    if np.allclose(np.sum(y_train_fixed, axis=1), 1):\n",
    "        y_train = y_train_fixed\n",
    "        y_test = y_test_fixed\n",
    "        print(\"Using one-hot encoded labels\")\n",
    "    else:\n",
    "        # If not proper one-hot, they might be class indices\n",
    "        # Convert to integers first, then to one-hot\n",
    "        y_train_int = np.argmax(y_train_fixed, axis=1)\n",
    "        y_test_int = np.argmax(y_test_fixed, axis=1)\n",
    "        y_train = to_categorical(y_train_int, num_classes=7)\n",
    "        y_test = to_categorical(y_test_int, num_classes=7)\n",
    "        print(\"Converted to proper one-hot encoding\")\n",
    "\n",
    "# Solution 2: If the above doesn't work, try flattening and reshaping\n",
    "# This handles cases where labels might be stored incorrectly\n",
    "else:\n",
    "    # Flatten the labels and take first 7 elements for each sample\n",
    "    y_train_flat = y_train.reshape(y_train.shape[0], -1)\n",
    "    y_test_flat = y_test.reshape(y_test.shape[0], -1)\n",
    "    \n",
    "    # Take first 7 elements (assuming they contain the class info)\n",
    "    y_train = y_train_flat[:, :7]\n",
    "    y_test = y_test_flat[:, :7]\n",
    "\n",
    "print(\"Final y_train shape:\", y_train.shape)\n",
    "print(\"Final y_test shape:\", y_test.shape)\n",
    "print(\"Sample final y_train[0]:\", y_train[0])\n",
    "\n",
    "# Verify the labels are properly formatted\n",
    "print(\"Sum of first few samples:\", np.sum(y_train[:5], axis=1))\n",
    "\n",
    "# Now compile and train the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=x_train, \n",
    "    y=y_train, \n",
    "    batch_size=128, \n",
    "    epochs=100, \n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d581cd-83c3-4dcd-9080-ecb10e9093fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
